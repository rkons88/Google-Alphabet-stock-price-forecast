{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f82c58",
   "metadata": {},
   "source": [
    "#### PROJECT GOAL: THE GOAL OF THE PROJECT IS TO TEST THE DEGREE OF EFFECTIVENESS OF SELECTED MACHINE LEARNING MODELS/ALGORITHMS TO PREDICT THE VALUE OF TIME SERIES DATA BASED ON THE GOOGLE/ALPHABET STOCK\n",
    "\n",
    "#### I CHOSE THIS COMPANY BECAUSE IT IS THE WORLD LARGEST TECH COMPANY AND I PERSONALLY OWN IT IN MY INVESTMENT PORTFOLIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import  metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c97c19",
   "metadata": {},
   "source": [
    "#### DATA IMPORT USING YFINANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba15e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download('GOOGL', index_col = 0, squeeze = True, parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dd4052",
   "metadata": {},
   "source": [
    "#### DATA PRINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5742da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cacdda9",
   "metadata": {},
   "source": [
    "#### CONCLUSION: COLUMNS IN IMPORTED DATA REPRESENT RESPECTIVELY: OPENING PRICE IN THE SESSION, MAXIMUM PRICE DURING THE SESSION, MINIMUM PRICE IN THE SESSION, CLOSING PRICE IN THE SESSION AND TRADING VOLUME, ROWS/INDEXES REPRESENT TRADING DAY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b71f83",
   "metadata": {},
   "source": [
    "#### DATA DIMENSIONS PRINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bab688",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a41dca6",
   "metadata": {},
   "source": [
    "#### CHECKING IF THERE ARE MISSING VALUES IN THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a60eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a562a",
   "metadata": {},
   "source": [
    "#### CONCLUSION: IMPORTED DATA IS CLEAN - NO MISSING VALUES PRESENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda53bbf",
   "metadata": {},
   "source": [
    "#### FILTERING ANALYZED DATA - WE ARE INTERESTED IN THE CLOSING PRICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b67cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d633747",
   "metadata": {},
   "source": [
    "#### PLOTTING CHART OF THE CLOSING PRICE OVER TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "data.plot()\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c7ae87",
   "metadata": {},
   "source": [
    "#### DEFINING FUNCTION TEST_STATIONARITY TO CHECK STATIONARITY OF TIME-SERIES DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43602f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(timeseries):\n",
    "    rolmean = timeseries.rolling(12).mean()#.rolling_mean(timeseries, window=12)\n",
    "    rolstd = timeseries.rolling(12).std()\n",
    "    \n",
    "    #Plot rolling statistics:\n",
    "    plt.figure(figsize=(20,10));\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    \n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909970c",
   "metadata": {},
   "source": [
    "#### TIME-SERIES DATA STATIONARITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8569c91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stationarity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092a5167",
   "metadata": {},
   "source": [
    "#### P-VALUE CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,pval,_,_,_,_ =adfuller(data, autolag='AIC')\n",
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a5667",
   "metadata": {},
   "source": [
    "#### P-VALUE CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9128532",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pval > 0.05:\n",
    "    print('pval > 0.05 -> ZERO HYPOTHESIS TRUE -> TIME-SERIES DATA IS NOT STATIONARY')\n",
    "else:\n",
    "    print('pval < = 0.05 -> ZERO HYPOTHESIS FALSE -> TIME-SERIES DATA IS STATIONARY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bc26fb",
   "metadata": {},
   "source": [
    "#### AUTO-CORRELATION CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e98a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "autocorrelation_plot(data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a0b1c",
   "metadata": {},
   "source": [
    "#### AUTO-CORRELATION CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(data.values, lags=40, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(data.values, lags=40, ax=ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ba586",
   "metadata": {},
   "source": [
    "#### DEFINING SIZE OF TEST DATA SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eb62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d237b",
   "metadata": {},
   "source": [
    "#### DATA TRANSFORMATION FOR LSTM NEURAL NETWORK PURPOSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b0e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lstm = data.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee3710",
   "metadata": {},
   "source": [
    "#### TRAIN-TEST DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217cd7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_size = int(len(data_lstm)*(1-test_size))\n",
    "test_data_size = len(data_lstm)-training_data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e1793",
   "metadata": {},
   "source": [
    "#### TRAIN-TEST DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec202521",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_lstm[0:training_data_size,:]\n",
    "test_data = data_lstm[training_data_size:len(data_lstm),:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8633869a",
   "metadata": {},
   "source": [
    "#### TRANSFORMING DIVIDED DATA TO FEED LSTM NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889742dc",
   "metadata": {},
   "source": [
    "#### DEFINING THE TIME_STEP PARAMETER I.E. THE NUMBER OF PAST OBSERVATIONS BASED ON WHICH WE WILL TRY TO PREDICT THE NEXT OBSERVATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bfc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b3d9c6",
   "metadata": {},
   "source": [
    "#### DEFINING CREATE_DATASET FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, time_step=time_step):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "X_train, y_train = create_dataset(train_data_scaled, time_step)\n",
    "X_test, y_test = create_dataset(test_data_scaled, time_step)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14458f",
   "metadata": {},
   "source": [
    "#### DEFINING LSTM NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm=Sequential()\n",
    "model_lstm.add(LSTM(50,return_sequences=True,input_shape=(time_step,1)))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(LSTM(50,return_sequences=True))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(LSTM(50))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(1))\n",
    "\n",
    "model_lstm.compile(loss='mean_squared_error', optimizer ='adam', metrics=['mse', 'mae'])\n",
    "\n",
    "model_lstm.fit(x=X_train, y=y_train, batch_size=15, epochs=30, shuffle=True, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b327f5",
   "metadata": {},
   "source": [
    "#### DATA PREDICTION WITH LSTM NEURAL NETWORK MODEL FOR TRAINING AND TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = model_lstm.predict(X_train)\n",
    "test_predict = model_lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f443d8a",
   "metadata": {},
   "source": [
    "#### TRANSFORMATION OF DATA FOR CORRECT PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24620dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict_inverted = scaler.inverse_transform(train_predict)\n",
    "test_predict_inverted = scaler.inverse_transform(test_predict)\n",
    "\n",
    "train_predict_inverted_zeros = np.zeros(time_step+1)\n",
    "train_predict_inverted_final = np.insert(train_predict_inverted, 0, train_predict_inverted_zeros)\n",
    "\n",
    "test_predict_inverted_zeros = np.zeros(train_predict_inverted_final.shape[0]+ time_step+1)\n",
    "test_predict_inverted_final= np.insert(test_predict_inverted, 0, test_predict_inverted_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce10bc",
   "metadata": {},
   "source": [
    "#### PLOTTING IMPORTED DATA AND PREDICTIONS USING LSTM NEURAL NETWORK MODEL FOR TRAINING AND TEST DATA SECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(train_predict_inverted_final, label='LSTM_train_pred')\n",
    "plt.plot(test_predict_inverted_final, label = 'LSTM_test_pred')\n",
    "plt.plot(data.values, label= 'data')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('OBSERVATION')\n",
    "plt.ylabel('PRICE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ddb69",
   "metadata": {},
   "source": [
    "#### CALCULATION OF QUALITY METRICS FOR PREDICTED VALUES FROM TEST DATA SECTION FOR LSTM NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784fcad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mean_squared_error = metrics.mean_squared_error(test_predict_inverted, data.values[-test_data_size+time_step+1:])\n",
    "\n",
    "lstm_mean_absolute_error = metrics.mean_absolute_error(test_predict_inverted, data.values[-test_data_size+time_step+1:])\n",
    "\n",
    "lstm_median_absolute_error = metrics.median_absolute_error(test_predict_inverted, data.values[-test_data_size+time_step+1:])\n",
    "\n",
    "lstm_explained_variance_score = metrics.explained_variance_score(test_predict_inverted, data.values[-test_data_size+time_step+1:])\n",
    "\n",
    "lstm_r2 = metrics.r2_score(test_predict_inverted, data.values[-test_data_size+time_step+1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ca1f48",
   "metadata": {},
   "source": [
    "#### CREATION AND ON-SCREEN PRINTING OF DATAFRAME WITH QUALITY METRICS FOR LSTM NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b768fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1 = {'r2': [lstm_r2],\n",
    "     'explained_variance_score': [lstm_explained_variance_score], \n",
    "     'median_absolute_error': [lstm_median_absolute_error],\n",
    "     'mean_squared_error' : [lstm_mean_squared_error],\n",
    "     'mean_absolute_error' : [lstm_mean_absolute_error],\n",
    "    }\n",
    "\n",
    "df_1 = pd.DataFrame(data=d_1)\n",
    "df_1.insert(loc=0, column='Method', value=['LSTM'])\n",
    "\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b3fd79",
   "metadata": {},
   "source": [
    "#### DEFINING SERIES_TO_SUPERVISED FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08289b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28aa93f",
   "metadata": {},
   "source": [
    "#### DEFINING RANGE FOR TRAIN-TEST DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b463f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_values = data.values\n",
    "\n",
    "data_train = data[:-test_data_size]\n",
    "data_test = data[-test_data_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499be5e1",
   "metadata": {},
   "source": [
    "#### PLOTTING CHART OF TRAIN AND TEST DATA BEFORE THE TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "data_train.plot(label = 'train')\n",
    "data_test.plot(label = 'test')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('DATE')\n",
    "plt.ylabel('PRICE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6f309f",
   "metadata": {},
   "source": [
    "#### TRANSFORMING AND PRINTING IMPORTED TIME-SERIES DATA USING PREVIOUSLY DEFINED FUNCTION SERIES_TO_SUPERVISED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe7a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['t'] = [x for x in data]\n",
    "\n",
    "dataframe = series_to_supervised(df, time_step, 1)\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b53dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataframe.values\n",
    "# split into input and output\n",
    "X = array[:,0:-1]\n",
    "y = array[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a676bbd",
   "metadata": {},
   "source": [
    "#### TRAIN-TEST DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5acfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9031252",
   "metadata": {},
   "source": [
    "#### DEFINING CROSS-VALIDATION PARAMETERS TO AVOID OVER-FITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1caba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=123\n",
    "kfold = model_selection.KFold(n_splits=5, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3943022f",
   "metadata": {},
   "source": [
    "#### SEARCHING FOR THE OPTIMAL DEGREE OF A POLYNOMIAL USING ELASTIC NET REGRESSION METHOD\n",
    "#### ANALYZED DEGREES OF POLYNOMIAL: FROM 1 TO 4\n",
    "#### ANALYZED ALPHA COEFFICIENT: 1, 2, 3\n",
    "#### RETURN OPTIMAL DEGREE OF POLYNOMIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_1 = GridSearchCV(make_pipeline(PolynomialFeatures(degree=2), ElasticNet(alpha=1, max_iter=1000, random_state=seed)),\n",
    "                    param_grid={'polynomialfeatures__degree': [1, 2, 3, 4],\n",
    "                    'elasticnet__alpha': [1, 2, 3]},\n",
    "                    cv=kfold,\n",
    "                    refit=True)\n",
    "\n",
    "grid_1.fit(X_train, y_train)\n",
    "grid_1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c966307a",
   "metadata": {},
   "source": [
    "#### SEARCHING FOR THE OPTIMAL DEGREE OF A POLYNOMIAL USING LASSO REGRESSION METHOD\n",
    "#### ANALYZED DEGREES OF POLYNOMIAL: FROM 1 TO 4\n",
    "#### ANALYZED ALPHA COEFFICIENT: 1, 2, 3\n",
    "#### RETURN OPTIMAL DEGREE OF POLYNOMIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_2 = GridSearchCV(make_pipeline(PolynomialFeatures(degree=2), Lasso(alpha=1, max_iter=1000, random_state=seed)),\n",
    "                    param_grid={'polynomialfeatures__degree': [1, 2, 3, 4],\n",
    "                    'lasso__alpha': [1, 2, 3]},\n",
    "                    cv=kfold,\n",
    "                    refit=True)\n",
    "\n",
    "grid_2.fit(X_train, y_train)\n",
    "grid_2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d1a324",
   "metadata": {},
   "source": [
    "#### SEARCHING FOR THE OPTIMAL DEGREE OF A POLYNOMIAL USING RIDGE REGRESSION METHOD\n",
    "#### ANALYZED DEGREES OF POLYNOMIAL: FROM 1 TO 4\n",
    "#### ANALYZED ALPHA COEFFICIENT: 1, 2, 3\n",
    "#### RETURN OPTIMAL DEGREE OF POLYNOMIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a8c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_3 = GridSearchCV(make_pipeline(PolynomialFeatures(degree=2), Ridge(alpha=1, max_iter=1000, random_state=seed)),\n",
    "                    param_grid={'polynomialfeatures__degree': [1, 2, 3, 4],\n",
    "                    'ridge__alpha': [1, 2, 3]},\n",
    "                    cv=kfold,\n",
    "                    refit=True)\n",
    "\n",
    "grid_3.fit(X_train, y_train)\n",
    "grid_3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328cbcec",
   "metadata": {},
   "source": [
    "#### SEARCHING FOR THE OPTIMAL DEGREE OF A POLYNOMIAL USING POLYNOMIAL REGRESSION METHOD.\n",
    "#### ANALYZING DEGREES OF POLYNOMIAL: FROM 1 TO 4\n",
    "#### RETURN OPTIMAL DEGREE OF POLYNOMIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_4 = GridSearchCV(make_pipeline(PolynomialFeatures(degree=2), linear_model.LinearRegression()),\n",
    "                    param_grid={'polynomialfeatures__degree': [1, 2, 3, 4]},\n",
    "                    cv=kfold,\n",
    "                    refit=True)\n",
    "\n",
    "grid_4.fit(X_train, y_train)\n",
    "grid_4.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d93e7e",
   "metadata": {},
   "source": [
    "#### DEFINING AND TRAINING MLP REGRESSOR NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f0a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_5 = GridSearchCV(MLPRegressor(hidden_layer_sizes=(100,100,100),activation='tanh',alpha=0.0001,max_iter=1000),\n",
    "                    param_grid={'hidden_layer_sizes': [(1000,1000,1000),(100,100,100),(10,10,10)],\n",
    "                                'alpha': [1, 10, 100 ,1000],\n",
    "                               'activation': ['identity', 'logistic', 'tanh', 'relu']                               \n",
    "                               },\n",
    "                    cv = kfold,\n",
    "                    n_jobs=1,\n",
    "                    refit=True)\n",
    "\n",
    "grid_5.fit(X_train,y_train)\n",
    "grid_5.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b05961",
   "metadata": {},
   "source": [
    "#### CREATION LIST OF OPTIMAL R^2, VAR, MAE, MSE PARAMETERS FOR ALL ANALYZED METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d433979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('ElasticNet', grid_1.best_estimator_))\n",
    "models.append(('Lasso', grid_2.best_estimator_))\n",
    "models.append(('Ridge', grid_3.best_estimator_))\n",
    "models.append(('LR', grid_4.best_estimator_))\n",
    "models.append(('MLP_R', grid_5.best_estimator_))\n",
    "\n",
    "r2 = []\n",
    "explained_variance_score = []\n",
    "median_absolute_error = []\n",
    "mean_squared_error = []\n",
    "mean_absolute_error = []\n",
    "\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(\"R^2: {}\".format(metrics.r2_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"Explained variance score: {}\".format( metrics.explained_variance_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"Median absolute error: {}\".format( metrics.median_absolute_error(y_test, model.predict(X_test)) ))\n",
    "    print(\"Mean squared error: {}\".format( metrics.mean_squared_error(y_test, model.predict(X_test)) ))\n",
    "    print(\"Mean absolute errors: {}\".format(metrics.mean_absolute_error(y_test, model.predict(X_test)) ))\n",
    "    r2.append(metrics.r2_score(y_test, model.predict(X_test)))\n",
    "    explained_variance_score.append(metrics.explained_variance_score(y_test, model.predict(X_test)))\n",
    "    median_absolute_error.append( metrics.median_absolute_error(y_test, model.predict(X_test)))\n",
    "    mean_squared_error.append(metrics.mean_squared_error(y_test, model.predict(X_test)))\n",
    "    mean_absolute_error.append(metrics.mean_absolute_error(y_test, model.predict(X_test)))\n",
    "\n",
    "print('LSTM')\n",
    "print(\"R^2: {}\".format(lstm_r2))\n",
    "print(\"Explained variance score: {}\".format(lstm_explained_variance_score))\n",
    "print(\"Median absolute error: {}\".format(lstm_median_absolute_error))\n",
    "print(\"Mean squared error: {}\".format(lstm_mean_absolute_error))\n",
    "print(\"Mean absolute errors: {}\".format(lstm_mean_absolute_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6efce7",
   "metadata": {},
   "source": [
    "#### CREATION AND PRINT OF DATAFRAME INCLUDING R^2, VAR, MAE, MSE PARAMETERS FOR ALLANALYZED METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effbb3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2 = {'r2': r2, \n",
    "     'explained_variance_score': explained_variance_score, \n",
    "     'median_absolute_error': median_absolute_error,\n",
    "     'mean_squared_error' : mean_squared_error,\n",
    "     'mean_absolute_error' : mean_absolute_error,\n",
    "    }\n",
    "\n",
    "df_2 = pd.DataFrame(data=d_2)\n",
    "\n",
    "df_2.insert(loc=0, column='Method', value=['ElasticNet_test_given','Lasso_test_given','Ridge_test_given', 'LR_test_given', 'MLP_R_test_given'])\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7468fe",
   "metadata": {},
   "source": [
    "#### PRINTING PREVIOUSLY CREATED DATAFRAME WITH QUALITY METRICS FOR LSTM NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df227322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dacf9b",
   "metadata": {},
   "source": [
    "#### PRINTING PREVIOUSLY CREATED DATAFRAME WITH QUALITY METRICS FOR THE REST OF ANALYZED MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54effd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc95b9d",
   "metadata": {},
   "source": [
    "#### MERGING BOTH DATAFRAMES WITH QUALITY METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0782493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1, df_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0fe80",
   "metadata": {},
   "source": [
    "#### PRINTING MERGED DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dffc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e4d837",
   "metadata": {},
   "source": [
    "#### FILTERING DATAFRAME FOR THE MAXIMUM R^2 VALUE CORRESPONDING WITH THE MOST EFFECTIVE MODEL/ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2329aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['r2'] == df['r2'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4087a",
   "metadata": {},
   "source": [
    "#### TRANSFORMATION OF DATA TO PLOT CORRECTLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f25ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_zeros = np.zeros(data_train.values.shape[0])\n",
    "data_test_chart= np.insert(data_test.values, 0, data_train_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3262371a",
   "metadata": {},
   "source": [
    "#### PLOT TRAINING DATA SECTION, TEST DATA SECTION AND PREDICTED DATA FOR ALL MODELS - MODELS PREDICT LAST 20% OBSERVATIONS FROM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(data_train.values, label = 'train')\n",
    "plt.plot(data_test_chart, label = 'test')\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for name, model in models: \n",
    "    data = np.zeros(data.shape[0], dtype=float)\n",
    "    data.fill(np.nan)\n",
    "    \n",
    "    for i in range(1,test_data_size):\n",
    "        point = np.array([data_values[ (data_values.shape[0]-((time_step+1*i))):(data_values.shape[0]-(1*i))]])\n",
    "        pre=model.predict(point)\n",
    "        data[-i]=pre\n",
    "        \n",
    "    all_data.append(data)\n",
    "        \n",
    "    plt.plot(data , label=name)\n",
    "    \n",
    "    \n",
    "plt.plot(test_predict_inverted_final, label='LSTM')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('AMOUNT OF PAST OBSERVATIONS')\n",
    "plt.ylabel('PRICE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2edbdc",
   "metadata": {},
   "source": [
    "#### PLOT TEST DATA SECTION AND PREDICTED DATA FOR ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c377a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NARYSOWANIE WYKRESU DLA CZĘŚCI TESTOWEJ NAUCZONYCH MODELI\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for name, model in models: \n",
    "    \n",
    "    for i in range (1,test_data_size):\n",
    "        data_chart = data_test.values\n",
    "        point = np.array([data_values[ (data_values.shape[0]-((time_step+1*i))):(data_values.shape[0]-(1*i))]])\n",
    "        pre=model.predict(point)\n",
    "        data[-i]=pre\n",
    "       \n",
    "    plt.plot( data[-i:] , label=name)\n",
    "\n",
    "plt.plot(data_chart[-i:], 'k--', label='test')\n",
    "plt.plot(test_predict_inverted_final[-i:], label='LSTM')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('AMOUNT OF PAST OBSERVATIONS')\n",
    "plt.ylabel('PRICE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343b74d7",
   "metadata": {},
   "source": [
    "#### PLOTTING LAST 450 OBSERVATIONS AND ITS PREDICTIONS FOR ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd421c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for name, model in models: \n",
    "    \n",
    "    for i in range (1,450):\n",
    "        data_chart = data_test.values\n",
    "    \n",
    "        point = np.array([data_values[ (data_values.shape[0]-((time_step+1*i))):(data_values.shape[0]-(1*i))]])\n",
    "        pre=model.predict(point)\n",
    "        data[-i]=pre\n",
    "       \n",
    "    plt.plot( data[-i:] , label=name)\n",
    "\n",
    "plt.plot(data_chart[-i:], 'k--', label='test')\n",
    "plt.plot(test_predict_inverted_final[-i:], label='LSTM')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('AMOUNT OF PAST OBSERVATIONS')\n",
    "plt.ylabel('PRICE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb2fb4",
   "metadata": {},
   "source": [
    "#### PLOTTING LAST 225 OBSERVATIONS AND ITS PREDICTIONS FOR ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392700f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for name, model in models: \n",
    "    \n",
    "    for i in range (1,225):\n",
    "        data_chart = data_test.values\n",
    "    \n",
    "        point = np.array([data_values[ (data_values.shape[0]-((time_step+1*i))):(data_values.shape[0]-(1*i))]])\n",
    "        pre=model.predict(point)\n",
    "        data[-i]=pre\n",
    "       \n",
    "    plt.plot( data[-i:] , label=name)\n",
    "\n",
    "plt.plot(data_chart[-i:], 'k--', label='test')\n",
    "plt.plot(test_predict_inverted_final[-i:], label='LSTM')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('AMOUNT OF PAST OBSERVATIONS')\n",
    "plt.ylabel('PRICE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1c31a",
   "metadata": {},
   "source": [
    "#### PLOTTING LAST 110 OBSERVATIONS AND ITS PREDICTIONS FOR ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for name, model in models: \n",
    "    \n",
    "    for i in range (1,110):\n",
    "        data_chart = data_test.values\n",
    "    \n",
    "        point = np.array([data_values[ (data_values.shape[0]-((time_step+1*i))):(data_values.shape[0]-(1*i))]])\n",
    "        pre=model.predict(point)\n",
    "        data[-i]=pre\n",
    "       \n",
    "    plt.plot( data[-i:] , label=name)\n",
    "\n",
    "plt.plot(data_chart[-i:], 'k--', label='test')\n",
    "plt.plot(test_predict_inverted_final[-i:], label='LSTM')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('AMOUNT OF PAST OBSERVATIONS')\n",
    "plt.ylabel('PRICE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622be9af",
   "metadata": {},
   "source": [
    "#### PLOTTING LAST 55 OBSERVATIONS AND ITS PREDICTIONS FOR ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for name, model in models: \n",
    "    \n",
    "    for i in range (1,55):\n",
    "        data_chart = data_test.values\n",
    "    \n",
    "        point = np.array([data_values[ (data_values.shape[0]-((time_step+1*i))):(data_values.shape[0]-(1*i))]])\n",
    "        pre=model.predict(point)\n",
    "        data[-i]=pre\n",
    "       \n",
    "    plt.plot( data[-i:] , label=name)\n",
    "\n",
    "plt.plot(data_chart[-i:], 'k--', label='test')\n",
    "plt.plot(test_predict_inverted_final[-i:], label='LSTM')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('AMOUNT OF PAST OBSERVATIONS')\n",
    "plt.ylabel('PRICE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a4ce0",
   "metadata": {},
   "source": [
    "#### PLOTTING LAST 25 OBSERVATIONS AND ITS PREDICTIONS FOR ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa0fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for name, model in models: \n",
    "    \n",
    "    for i in range (1,25):\n",
    "        data_chart = data_test.values\n",
    "    \n",
    "        point = np.array([data_values[ (data_values.shape[0]-((time_step+1*i))):(data_values.shape[0]-(1*i))]])\n",
    "        pre=model.predict(point)\n",
    "        data[-i]=pre\n",
    "       \n",
    "    plt.plot( data[-i:] , label=name)\n",
    "\n",
    "plt.plot(data_chart[-i:], 'k--', label='test')\n",
    "plt.plot(test_predict_inverted_final[-i:], label='LSTM')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('Ilosc ostatnich dni')\n",
    "plt.ylabel('Cena')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c04d32d",
   "metadata": {},
   "source": [
    "#### PLOTTING LAST 12 OBSERVATIONS AND ITS PREDICTIONS FOR ALL MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3eda8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for name, model in models: \n",
    "    \n",
    "    for i in range (1,12):\n",
    "        data_chart = data_test.values\n",
    "    \n",
    "        point = np.array([data_values[ (data_values.shape[0]-((time_step+1*i))):(data_values.shape[0]-(1*i))]])\n",
    "        pre=model.predict(point)\n",
    "        data[-i]=pre\n",
    "       \n",
    "    plt.plot( data[-i:] , label=name)\n",
    "\n",
    "plt.plot(data_chart[-i:], 'k--', label='test')\n",
    "plt.plot(test_predict_inverted_final[-i:], label='LSTM')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('Ilosc ostatnich dni')\n",
    "plt.ylabel('Cena')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022782e6",
   "metadata": {},
   "source": [
    "#### CONCLUSION_1: DESPITE THE FACT THAT THE ANALYZED MODELS PREDICT OBSERVATIONS IN SATISFACTORY WAY FOR TEST DATA, IT IS IMPORTANT TO REMEMBER THAT THE MODEL PREDICTS VALUES BASED ON OBSERVATIONS FROM THE PAST, MODEL IS SENSITIVE TO UNEXPECTED EVENTS HAVING LOW PROBABILITY AND INTRODUCING HIGH VOLATILITY TO THE STOCK SO-CALLED \"BLACK SWANS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bccbebf",
   "metadata": {},
   "source": [
    "#### CONCLUSION_2: LSTM NEURAL NETWORK DESPITE BEING A MORE COMPLEX TOOL FOR TIME SERIES PREDICTION THAN OTHER MODELS ACHIEVES RESULTS LESS SATISFACTORY THAN SIMPLER METHODS, WHICH ADDITIONALLY COMPUTE FASTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec55b26",
   "metadata": {},
   "source": [
    "#### CONCLUSION_3: TO GET BETTER RESULTS - ESPECIALLY FOR THE LSTM NEURAL NETWORK MODEL ONE SHOULD INCREASE THE TIME_STEP PARAMETER WHICH DEFINES THE NUMBER OF \"PAST\" OBSERVATIONS ON THE BASIS WHICH WE PREDICT THE \"FUTURE\" OBSERVATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107cb91",
   "metadata": {},
   "source": [
    "#### CONCLUSION_4: SIMPLER METHODS - LINEAR REGRESSION, LASSO REGRESSION, RIDGE REGRESSION, ELASTIC_NET ACHIEVE BETTER RESULTS THAN LSTM NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bec22d",
   "metadata": {},
   "source": [
    "#### DOWNLOADING DATA USING YAHOO FINANCE API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download('GOOGL', index_col = 0, squeeze = True, parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870441cb",
   "metadata": {},
   "source": [
    "#### FILTERING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f954647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1585a5bd",
   "metadata": {},
   "source": [
    "#### EXTRACTING DATA VALUES FROM ALREADY FILTERED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20398bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_values = data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8029b51",
   "metadata": {},
   "source": [
    "#### DEFINING TRAINING DATA SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8cdb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_values[:-test_data_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a1e33",
   "metadata": {},
   "source": [
    "#### APPLYING SERIES_TO_SUPERVISED FUNCTION ON TRAINING DATA SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['t'] = [x for x in data_train]\n",
    "\n",
    "dataframe = series_to_supervised(df, time_step, 1)\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataframe.values\n",
    "# split into input and output\n",
    "X = array[:,0:-1]\n",
    "y = array[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550e9d4c",
   "metadata": {},
   "source": [
    "#### COMPUTING TEST DATA FOR ALL ML METHODS - TEST DATA IS CREATED USING PREDICTIONS FROM TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictor = X[-1:].reshape(1,-1)\n",
    "training_predictor = X[-1:].tolist()[0]\n",
    "\n",
    "\n",
    "predictors = []\n",
    "test_list = []\n",
    "test_values_real = []\n",
    "\n",
    "for predictor in training_predictor:\n",
    "    \n",
    "    predictors.append(predictor)\n",
    "    \n",
    "print('PREDICTORS FROM TRAINING DATA: {}' .format(predictors))\n",
    "         \n",
    "for name, model in models:\n",
    "        \n",
    "    for i in range(test_data_size):\n",
    "                        \n",
    "        test_val= model.predict(test_predictor)\n",
    "        test_val_clean = test_val.item()\n",
    "    \n",
    "    #print('PREDICTION FROM PREDICTORS: {}' .format(test_val_clean))\n",
    "        \n",
    "        test_list.append(test_val_clean)\n",
    "        predictors.append(test_val_clean)\n",
    "    \n",
    "        del predictors[0]\n",
    "    \n",
    "    #print('NEW PREDICTORS TO FORM TEST DATA: {}' .format(predictors))\n",
    "    \n",
    "        test_predictor = np.array(predictors).reshape(1,-1)\n",
    "        \n",
    "    test_list_array = np.array(test_list)\n",
    "    test_values_real.append(test_list_array)\n",
    "        \n",
    "    print('COMPUTED PREDICTIONS FOR {} TO FORM TEST DATA: {}'.format(name, test_list_array))\n",
    "        \n",
    "    test_list.clear()\n",
    "        \n",
    "    del test_predictor\n",
    "        \n",
    "    test_predictor = X[-1:].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1031c77",
   "metadata": {},
   "source": [
    "#### PRINTING REGRESSION-ACCURACY SCORES FOR ALL ML MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598750fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test_values_real:\n",
    "    \n",
    "    print(\"R^2: {}\".format(metrics.r2_score(y_test,i[:-1])))\n",
    "    print(\"Explained variance score: {}\".format( metrics.explained_variance_score(y_test,i[:-1])))\n",
    "    print(\"Median absolute error: {}\".format( metrics.median_absolute_error(y_test,i[:-1])))\n",
    "    print(\"Mean squared error: {}\".format( metrics.mean_squared_error(y_test,i[:-1])))\n",
    "    print(\"Mean absolute errors: {}\".format(metrics.mean_absolute_error(y_test,i[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c08fcf",
   "metadata": {},
   "source": [
    "#### CREATING LISTS WITH REGRESSION-ACCURACY SCORES FOR ALL ML MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = []\n",
    "explained_variance_score = []\n",
    "median_absolute_error = []\n",
    "mean_squared_error = []\n",
    "mean_absolute_error = []\n",
    "\n",
    "for i in test_values_real:\n",
    "    r2.append(metrics.r2_score(y_test, i[:-1]))\n",
    "    explained_variance_score.append(metrics.explained_variance_score(y_test, i[:-1]))\n",
    "    median_absolute_error.append( metrics.median_absolute_error(y_test, i[:-1]))\n",
    "    mean_squared_error.append(metrics.mean_squared_error(y_test, i[:-1]))\n",
    "    mean_absolute_error.append(metrics.mean_absolute_error(y_test, i[:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a7576",
   "metadata": {},
   "source": [
    "#### CREATING DATAFRAME WITH REGRESSION-ACCURACY SCORES FOR ALL ML MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ac35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_3 = {'r2': r2, \n",
    "     'explained_variance_score': explained_variance_score, \n",
    "     'median_absolute_error': median_absolute_error,\n",
    "     'mean_squared_error' : mean_squared_error,\n",
    "     'mean_absolute_error' : mean_absolute_error,\n",
    "    }\n",
    "\n",
    "df_3 = pd.DataFrame(data=d_3)\n",
    "\n",
    "df_3.insert(loc=0, column='Method', value=['ElasticNet_test_predicted','Lasso_test_predicted','Ridge_test_predicted', 'LR_test_predicted', 'MLP_R_test_predicted'])\n",
    "\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e47824",
   "metadata": {},
   "source": [
    "#### JOINING ALL CREATED DATAFRAMES WITH REGRESSION-ACCURACY SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_2, df_3, df_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317c1b3",
   "metadata": {},
   "source": [
    "#### PRINTING ML MODEL WITH HIGHEST R^2 SCORE WHICH REPRESENTS BEST APPROXIMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a01908",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['r2'] == df['r2'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56894a62",
   "metadata": {},
   "source": [
    "#### CONCLUSION_5: TO SIMULATE REALISTIC ENVIRONMENT BY ADDING PREDICTIONS TO NON-EXISTING TEST DATA, PREDICTION SCORE FOR ALL ANALYZED ML MODELS DETERIORATES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c83fa2",
   "metadata": {},
   "source": [
    "#### CONCLUSION_6: TO SIMULATE REALISTIC ENVIRONMENT BY ADDING PREDICTIONS TO NON-EXISTING TEST DATA, PREDICTION SCORE FOR ALL ANALYZED ML MODELS ARE SIMILAR TO RESULTS ACHIEVED WITH LSTM NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6270f",
   "metadata": {},
   "source": [
    "#### CONCLUSION_7: STILL, AFTER CONDUCTING SIMULATIONS IN REALISTIC ENVIRONMENT, TIME OF COMPUTING FOR SIMPLE ML METHODS ARE FASTER THAN LSTM NEURAL NETWORK AND RESULTS ACHIEVED ARE SIMILAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ccedc0",
   "metadata": {},
   "source": [
    "#### CONCLUSION_8: CONDUCTING SIMULATIONS FOR ALREADY GIVEN TEST DATA FOR ALL ML MODELS PRODUCES BETTER RESULTS BUT ACHIEVED RESULTS DOES NOT REPRESENT REALISTIC ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb9bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372219b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b9dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
